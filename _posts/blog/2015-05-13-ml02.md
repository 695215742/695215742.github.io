---
layout: post
title: Gradient Descent Algorithm
description: 
category: blog
---

#####Gradient Descent Algorithm

* 	目的：求出局部最优的hypothesis:H(x)(使cost function J(a,b,...) 局部最优)

*	定义:
		* cost function：J(a,b,...)
		* J(a,b,...)的梯度(即导数):d(J),d(J)(a,b,...)即J在(a,b,...)处的导数

*	步骤

		* (1):选取一个起点:Point:(a1,b1,...)，J(a1,b1,...)
		* (2) Point := Point- α * d(J)(a1,b1,...)，不断替换Point ，直到最终收敛(convergence)。
		
对于复杂的函数，Gradient Descent只能找到一个局部最优的解，但是对于Hypothesis 是 linear function的情况，Gradient肯定能找到一个全局最优的解。

α控制每一步迈出的大小

* 太小增加了循环的次数

* 太大会越过optimize point，无法达到convergence

#####Batch :

Batch GD Algorithm是指使用了所有数据的GD Algorithm

